import os
import sys
import argparse
from pathlib import Path
import numpy as np
from PIL import Image
import torch
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
repo_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if repo_root not in sys.path:
    sys.path.insert(0, repo_root)

from vessel_segmentation.model import VesselSETR
from vessel_segmentation.config import Config


class PredictionDataset(Dataset):
    """é¢„æµ‹æ•°æ®é›†"""
    def __init__(self, image_dir, image_size=512):
        self.image_dir = Path(image_dir)
        self.image_size = image_size
        
        # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        self.image_files = sorted([
            f for f in self.image_dir.glob('*')
            if f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff']
        ])
        
        if len(self.image_files) == 0:
            raise ValueError(f"åœ¨ {image_dir} ä¸­æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
        
        print(f"æ‰¾åˆ° {len(self.image_files)} å¼ å¾…é¢„æµ‹å›¾ç‰‡")
    
    def __len__(self):
        return len(self.image_files)
    
    def __getitem__(self, idx):
        img_path = self.image_files[idx]
        
        # è¯»å–å›¾ç‰‡
        image = Image.open(img_path).convert('RGB')
        original_size = image.size  # (width, height)
        
        # è°ƒæ•´å¤§å°ç”¨äºæ¨¡å‹æ¨ç†
        image_resized = image.resize((self.image_size, self.image_size), Image.BILINEAR)
        
        # è½¬æ¢ä¸ºtensorå¹¶å½’ä¸€åŒ–ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
        image_tensor = torch.from_numpy(np.array(image_resized)).float()
        image_tensor = image_tensor.permute(2, 0, 1) / 255.0  # [C, H, W]
        
        # ä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„å½’ä¸€åŒ–
        from torchvision import transforms as T
        normalize = T.Normalize(mean=[0.33, 0.15, 0.06], std=[0.24, 0.12, 0.05])
        image_tensor = normalize(image_tensor)
        
        return {
            'image': image_tensor,
            'original_size': original_size,
            'filename': img_path.name
        }


def predict(
    image_dir,
    output_dir,
    checkpoint_path,
    image_size=512,
    batch_size=8,
    device='cuda',
    resize_to_original=True,
    save_probability=False
):
    """
    å¯¹å›¾ç‰‡è¿›è¡Œæ‰¹é‡é¢„æµ‹
    
    Args:
        image_dir: è¾“å…¥å›¾ç‰‡ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        checkpoint_path: æ¨¡å‹checkpointè·¯å¾„
        image_size: æ¨¡å‹è¾“å…¥å°ºå¯¸
        batch_size: æ‰¹æ¬¡å¤§å°
        device: è®¾å¤‡
        resize_to_original: æ˜¯å¦å°†é¢„æµ‹ç»“æœè°ƒæ•´å›åŸå§‹å°ºå¯¸
        save_probability: æ˜¯å¦ä¿å­˜æ¦‚ç‡å›¾
    """
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    mask_dir = output_dir / 'masks'
    mask_dir.mkdir(exist_ok=True)
    
    if save_probability:
        prob_dir = output_dir / 'probabilities'
        prob_dir.mkdir(exist_ok=True)
    
    # åŠ è½½æ•°æ®é›†
    dataset = PredictionDataset(image_dir, image_size)
    dataloader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=4,
        pin_memory=True
    )
    
    # åŠ è½½æ¨¡å‹
    print(f"åŠ è½½æ¨¡å‹: {checkpoint_path}")
    config = Config()
    model = VesselSETR(
        img_size=config.input_size,
        patch_size=config.patch_size,
        num_classes=config.num_classes,
        embed_dim=config.hidden_size,
        num_layers=config.num_layers,
        num_heads=config.num_heads
    )
    
    # åŠ è½½æƒé‡
    try:
        checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
    except TypeError:
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
        print(f"Checkpoint info:")
        if 'epoch' in checkpoint:
            print(f"  - Epoch: {checkpoint['epoch']}")
        if 'val_dice' in checkpoint:
            print(f"  - Val Dice: {checkpoint['val_dice']:.4f}")
        if 'val_iou' in checkpoint:
            print(f"  - Val IoU: {checkpoint['val_iou']:.4f}")
    else:
        model.load_state_dict(checkpoint)
    
    model = model.to(device)
    model.eval()
    
    print(f"\nå¼€å§‹é¢„æµ‹...")
    print(f"è¾“å…¥ç›®å½•: {image_dir}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print(f"æ‰¹æ¬¡å¤§å°: {batch_size}")
    print(f"è®¾å¤‡: {device}")
    print(f"è°ƒæ•´å›åŸå§‹å°ºå¯¸: {resize_to_original}")
    print(f"=" * 60)
    
    total_images = 0
    
    with torch.no_grad():
        for batch in tqdm(dataloader, desc="é¢„æµ‹ä¸­"):
            images = batch['image'].to(device)
            original_sizes = batch['original_size']
            filenames = batch['filename']
            
            # é¢„æµ‹
            outputs = model(images)
            
            # è·å–é¢„æµ‹ç±»åˆ«
            predictions = torch.argmax(outputs, dim=1).cpu().numpy()
            
            # è·å–æ¦‚ç‡ï¼ˆsoftmaxï¼‰
            if save_probability:
                probabilities = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()
            
            # å¤„ç†æ¯å¼ å›¾ç‰‡
            for i in range(len(filenames)):
                pred_mask = predictions[i]
                filename = filenames[i]
                original_size = (original_sizes[0][i].item(), original_sizes[1][i].item())
                
                # è°ƒæ•´maskå°ºå¯¸
                if resize_to_original:
                    mask_pil = Image.fromarray((pred_mask * 255).astype(np.uint8))
                    mask_pil = mask_pil.resize(original_size, Image.NEAREST)
                    pred_mask_final = (np.array(mask_pil) > 127).astype(np.uint8)
                else:
                    pred_mask_final = pred_mask.astype(np.uint8)
                
                # ä¿å­˜mask (0æˆ–255)
                mask_path = mask_dir / filename.replace('.jpg', '.png')
                Image.fromarray((pred_mask_final * 255).astype(np.uint8)).save(mask_path)
                
                # ä¿å­˜æ¦‚ç‡å›¾
                if save_probability:
                    prob_map = probabilities[i]
                    if resize_to_original:
                        prob_pil = Image.fromarray((prob_map * 255).astype(np.uint8))
                        prob_pil = prob_pil.resize(original_size, Image.BILINEAR)
                        prob_map = np.array(prob_pil).astype(np.float32) / 255.0
                    
                    prob_path = prob_dir / filename.replace('.jpg', '.png')
                    Image.fromarray((prob_map * 255).astype(np.uint8)).save(prob_path)
                
                total_images += 1
    
    print(f"\nâœ… é¢„æµ‹å®Œæˆï¼")
    print(f"   å¤„ç†å›¾ç‰‡æ•°: {total_images}")
    print(f"   é¢„æµ‹maskä¿å­˜åœ¨: {mask_dir}")
    if save_probability:
        print(f"   æ¦‚ç‡å›¾ä¿å­˜åœ¨: {prob_dir}")
    
    # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    vessel_pixels = []
    for mask_file in mask_dir.glob('*.png'):
        mask = np.array(Image.open(mask_file))
        vessel_ratio = (mask > 127).sum() / mask.size
        vessel_pixels.append(vessel_ratio)
    
    if vessel_pixels:
        print(f"   å¹³å‡è¡€ç®¡å æ¯”: {np.mean(vessel_pixels)*100:.2f}%")
        print(f"   æœ€å°è¡€ç®¡å æ¯”: {np.min(vessel_pixels)*100:.2f}%")
        print(f"   æœ€å¤§è¡€ç®¡å æ¯”: {np.max(vessel_pixels)*100:.2f}%")


def main():
    parser = argparse.ArgumentParser(description='è¡€ç®¡åˆ†å‰²é¢„æµ‹')
    parser.add_argument('--image_dir', type=str, required=True,
                        help='è¾“å…¥å›¾ç‰‡ç›®å½•')
    parser.add_argument('--output_dir', type=str, required=True,
                        help='è¾“å‡ºç›®å½•')
    parser.add_argument('--checkpoint', type=str, required=True,
                        help='æ¨¡å‹checkpointè·¯å¾„')
    parser.add_argument('--image_size', type=int, default=512,
                        help='æ¨¡å‹è¾“å…¥å°ºå¯¸')
    parser.add_argument('--batch_size', type=int, default=8,
                        help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--device', type=str, default='cuda',
                        help='è®¾å¤‡ (cuda/cpu)')
    parser.add_argument('--no_resize', action='store_true',
                        help='ä¸å°†é¢„æµ‹ç»“æœè°ƒæ•´å›åŸå§‹å°ºå¯¸')
    parser.add_argument('--save_probability', action='store_true',
                        help='ä¿å­˜æ¦‚ç‡å›¾')
    parser.add_argument('--flag', type=str, default=None,
                        help='å®éªŒæ ‡è¯†flag, è‹¥æä¾›åˆ™åœ¨è¾“å‡ºç›®å½•ä¸‹åˆ›å»ºè¯¥å­ç›®å½•ç”¨äºåŒºåˆ†ä¿å­˜')
    
    args = parser.parse_args()
    
    # å¤„ç†flagå­ç›®å½•
    resolved_output_dir = args.output_dir
    if args.flag:
        resolved_output_dir = str(Path(args.output_dir) / args.flag)

    predict(
        image_dir=args.image_dir,
        output_dir=resolved_output_dir,
        checkpoint_path=args.checkpoint,
        image_size=args.image_size,
        batch_size=args.batch_size,
        device=args.device,
        resize_to_original=not args.no_resize,
        save_probability=args.save_probability
    )


if __name__ == '__main__':
    main()
